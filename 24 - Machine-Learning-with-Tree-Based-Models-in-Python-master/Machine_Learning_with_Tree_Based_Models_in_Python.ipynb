{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your first classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "wbc = pd.read_csv('wbc.csv')\n",
    "X = wbc[['radius_mean', 'concave points_mean']]\n",
    "y = wbc['diagnosis'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "SEED = 1 \n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=SEED)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy: {:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression vs classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_regions(X, y, clf,\n",
    "                          feature_index=None,\n",
    "                          filler_feature_values=None,\n",
    "                          filler_feature_ranges=None,\n",
    "                          ax=None,\n",
    "                          X_highlight=None,\n",
    "                          res=0.02, legend=1,\n",
    "                          hide_spines=True,\n",
    "                          markers='s^oxv<>',\n",
    "                          colors='red,blue,limegreen,gray,cyan'):\n",
    "    \"\"\"Plot decision regions of a classifier.\n",
    "\n",
    "    Please note that this functions assumes that class labels are\n",
    "    labeled consecutively, e.g,. 0, 1, 2, 3, 4, and 5. If you have class\n",
    "    labels with integer labels > 4, you may want to provide additional colors\n",
    "    and/or markers as `colors` and `markers` arguments.\n",
    "    See http://matplotlib.org/examples/color/named_colors.html for more\n",
    "    information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape = [n_samples, n_features]\n",
    "        Feature Matrix.\n",
    "    y : array-like, shape = [n_samples]\n",
    "        True class labels.\n",
    "    clf : Classifier object.\n",
    "        Must have a .predict method.\n",
    "    feature_index : array-like (default: (0,) for 1D, (0, 1) otherwise)\n",
    "        Feature indices to use for plotting. The first index in\n",
    "        `feature_index` will be on the x-axis, the second index will be\n",
    "        on the y-axis.\n",
    "    filler_feature_values : dict (default: None)\n",
    "        Only needed for number features > 2. Dictionary of feature\n",
    "        index-value pairs for the features not being plotted.\n",
    "    filler_feature_ranges : dict (default: None)\n",
    "        Only needed for number features > 2. Dictionary of feature\n",
    "        index-value pairs for the features not being plotted. Will use the\n",
    "        ranges provided to select training samples for plotting.\n",
    "    ax : matplotlib.axes.Axes (default: None)\n",
    "        An existing matplotlib Axes. Creates\n",
    "        one if ax=None.\n",
    "    X_highlight : array-like, shape = [n_samples, n_features] (default: None)\n",
    "        An array with data points that are used to highlight samples in `X`.\n",
    "    res : float or array-like, shape = (2,) (default: 0.02)\n",
    "        Grid width. If float, same resolution is used for both the x- and\n",
    "        y-axis. If array-like, the first item is used on the x-axis, the\n",
    "        second is used on the y-axis. Lower values increase the resolution but\n",
    "        slow down the plotting.\n",
    "    hide_spines : bool (default: True)\n",
    "        Hide axis spines if True.\n",
    "    legend : int (default: 1)\n",
    "        Integer to specify the legend location.\n",
    "        No legend if legend is 0.\n",
    "    markers : str (default 's^oxv<>')\n",
    "        Scatterplot markers.\n",
    "    colors : str (default 'red,blue,limegreen,gray,cyan')\n",
    "        Comma separated list of colors.\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    ax : matplotlib.axes.Axes object\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    check_Xy(X, y, y_int=True)  # Validate X and y arrays\n",
    "    dim = X.shape[1]\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if isinstance(res, float):\n",
    "        xres, yres = res, res\n",
    "    else:\n",
    "        try:\n",
    "            xres, yres = res\n",
    "        except ValueError:\n",
    "            raise ValueError('Unable to unpack res. Expecting '\n",
    "                             'array-like input of length 2.')\n",
    "\n",
    "    plot_testdata = True\n",
    "    if not isinstance(X_highlight, np.ndarray):\n",
    "        if X_highlight is not None:\n",
    "            raise ValueError('X_highlight must be a NumPy array or None')\n",
    "        else:\n",
    "            plot_testdata = False\n",
    "    elif len(X_highlight.shape) < 2:\n",
    "        raise ValueError('X_highlight must be a 2D array')\n",
    "\n",
    "    if feature_index is not None:\n",
    "        # Unpack and validate the feature_index values\n",
    "        if dim == 1:\n",
    "            raise ValueError(\n",
    "                'feature_index requires more than one training feature')\n",
    "        try:\n",
    "            x_index, y_index = feature_index\n",
    "        except ValueError:\n",
    "            raise ValueError(\n",
    "                'Unable to unpack feature_index. Make sure feature_index '\n",
    "                'only has two dimensions.')\n",
    "        try:\n",
    "            X[:, x_index], X[:, y_index]\n",
    "        except IndexError:\n",
    "            raise IndexError(\n",
    "                'feature_index values out of range. X.shape is {}, but '\n",
    "                'feature_index is {}'.format(X.shape, feature_index))\n",
    "    else:\n",
    "        feature_index = (0, 1)\n",
    "        x_index, y_index = feature_index\n",
    "\n",
    "    # Extra input validation for higher number of training features\n",
    "    if dim > 2:\n",
    "        if filler_feature_values is None:\n",
    "            raise ValueError('Filler values must be provided when '\n",
    "                             'X has more than 2 training features.')\n",
    "\n",
    "        if filler_feature_ranges is not None:\n",
    "            if not set(filler_feature_values) == set(filler_feature_ranges):\n",
    "                raise ValueError(\n",
    "                    'filler_feature_values and filler_feature_ranges must '\n",
    "                    'have the same keys')\n",
    "\n",
    "        # Check that all columns in X are accounted for\n",
    "        column_check = np.zeros(dim, dtype=bool)\n",
    "        for idx in filler_feature_values:\n",
    "            column_check[idx] = True\n",
    "        for idx in feature_index:\n",
    "            column_check[idx] = True\n",
    "        if not all(column_check):\n",
    "            missing_cols = np.argwhere(~column_check).flatten()\n",
    "            raise ValueError(\n",
    "                'Column(s) {} need to be accounted for in either '\n",
    "                'feature_index or filler_feature_values'.format(missing_cols))\n",
    "\n",
    "    marker_gen = cycle(list(markers))\n",
    "\n",
    "    n_classes = np.unique(y).shape[0]\n",
    "    colors = colors.split(',')\n",
    "    colors_gen = cycle(colors)\n",
    "    colors = [next(colors_gen) for c in range(n_classes)]\n",
    "\n",
    "    # Get minimum and maximum\n",
    "    x_min, x_max = X[:, x_index].min() - 1, X[:, x_index].max() + 1\n",
    "    if dim == 1:\n",
    "        y_min, y_max = -1, 1\n",
    "    else:\n",
    "        y_min, y_max = X[:, y_index].min() - 1, X[:, y_index].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, xres),\n",
    "                         np.arange(y_min, y_max, yres))\n",
    "\n",
    "    if dim == 1:\n",
    "        X_predict = np.array([xx.ravel()]).T\n",
    "    else:\n",
    "        X_grid = np.array([xx.ravel(), yy.ravel()]).T\n",
    "        X_predict = np.zeros((X_grid.shape[0], dim))\n",
    "        X_predict[:, x_index] = X_grid[:, 0]\n",
    "        X_predict[:, y_index] = X_grid[:, 1]\n",
    "        if dim > 2:\n",
    "            for feature_idx in filler_feature_values:\n",
    "                X_predict[:, feature_idx] = filler_feature_values[feature_idx]\n",
    "    Z = clf.predict(X_predict)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot decisoin region\n",
    "    ax.contourf(xx, yy, Z,\n",
    "                alpha=0.3,\n",
    "                colors=colors,\n",
    "                levels=np.arange(Z.max() + 2) - 0.5)\n",
    "\n",
    "    ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n",
    "\n",
    "    # Scatter training data samples\n",
    "    for idx, c in enumerate(np.unique(y)):\n",
    "        if dim == 1:\n",
    "            y_data = [0 for i in X[y == c]]\n",
    "            x_data = X[y == c]\n",
    "        elif dim == 2:\n",
    "            y_data = X[y == c, y_index]\n",
    "            x_data = X[y == c, x_index]\n",
    "        elif dim > 2 and filler_feature_ranges is not None:\n",
    "            class_mask = y == c\n",
    "            feature_range_mask = get_feature_range_mask(\n",
    "                            X, filler_feature_values=filler_feature_values,\n",
    "                            filler_feature_ranges=filler_feature_ranges)\n",
    "            y_data = X[class_mask & feature_range_mask, y_index]\n",
    "            x_data = X[class_mask & feature_range_mask, x_index]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        ax.scatter(x=x_data,\n",
    "                   y=y_data,\n",
    "                   alpha=0.8,\n",
    "                   c=colors[idx],\n",
    "                   marker=next(marker_gen),\n",
    "                   edgecolor='black',\n",
    "                   label=c)\n",
    "\n",
    "    if hide_spines:\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    if dim == 1:\n",
    "        ax.axes.get_yaxis().set_ticks([])\n",
    "\n",
    "    if legend:\n",
    "        if dim > 2 and filler_feature_ranges is None:\n",
    "            pass\n",
    "        else:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.legend(handles, labels,\n",
    "                      framealpha=0.3, scatterpoints=1, loc=legend)\n",
    "\n",
    "    if plot_testdata:\n",
    "        if dim == 1:\n",
    "            x_data = X_highlight\n",
    "            y_data = [0 for i in X_highlight]\n",
    "        elif dim == 2:\n",
    "            x_data = X_highlight[:, x_index]\n",
    "            y_data = X_highlight[:, y_index]\n",
    "        else:\n",
    "            feature_range_mask = get_feature_range_mask(\n",
    "                    X_highlight, filler_feature_values=filler_feature_values,\n",
    "                    filler_feature_ranges=filler_feature_ranges)\n",
    "            y_data = X_highlight[feature_range_mask, y_index]\n",
    "            x_data = X_highlight[feature_range_mask, x_index]\n",
    "\n",
    "        ax.scatter(x_data,\n",
    "                   y_data,\n",
    "                   c='',\n",
    "                   edgecolor='black',\n",
    "                   alpha=1.0,\n",
    "                   linewidths=1,\n",
    "                   marker='o',\n",
    "                   s=80)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labeled_decision_regions(X,y, models):    \n",
    "    '''\n",
    "    Function producing a scatter plot of the instances contained \n",
    "    in the 2D dataset (X,y) along with the decision \n",
    "    regions of two trained classification models contained in the\n",
    "    list 'models'.\n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pandas DataFrame corresponding to two numerical features \n",
    "    y: pandas Series corresponding the class labels\n",
    "    models: list containing two trained classifiers \n",
    "    \n",
    "    '''\n",
    "    if len(models) != 2:\n",
    "        raise Exception('''\n",
    "        Models should be a list containing only two trained classifiers.\n",
    "        ''')\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        raise Exception('''\n",
    "        X has to be a pandas DataFrame with two numerical features.\n",
    "        ''')\n",
    "    if not isinstance(y, pd.Series):\n",
    "        raise Exception('''\n",
    "        y has to be a pandas Series corresponding to the labels.\n",
    "        ''')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6.0,2.7), sharey=True)\n",
    "    for i, model in enumerate(models):\n",
    "        plot_decision_regions(X.values,y.values, model, legend= 2, ax = ax[i])\n",
    "        ax[i].set_title(model.__class__.__name__)\n",
    "        ax[i].set_xlabel(X.columns[0])\n",
    "        if i == 0:\n",
    "            ax[i].set_ylabel(X.columns[1])\n",
    "        ax[i].set_ylim(X.values[:,1].min(), X.values[:,1].max())\n",
    "        ax[i].set_xlim(X.values[:,0].min(), X.values[:,0].max())\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression from sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instatiate logreg\n",
    "logreg = LogisticRegression(solver = 'liblinear', random_state=1)\n",
    "\n",
    "# Fit logreg to the training set\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Define a list called clfs containing the two classifiers logreg and dt\n",
    "clfs = [logreg, dt]\n",
    "\n",
    "# Review the decision regions of the two classifiers\n",
    "# plot_labeled_decision_regions(X_test, y_test, clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using entropy as a criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wbc[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
    "       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]\n",
    "y = wbc['diagnosis'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=8, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(max_depth = 8, criterion='entropy', random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=8, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dt_gini, set 'gini' as the information criterion\n",
    "dt_gini = DecisionTreeClassifier(max_depth = 8, criterion='gini', random_state=1)\n",
    "\n",
    "# Fit dt_gini to the training set\n",
    "dt_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy vs Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using entropy:  0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score from sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred = dt_entropy.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print accuracy_entropy\n",
    "print('Accuracy achieved by using entropy: ', accuracy_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using the gini index:  0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "# Use dt_entropy to predict test set labels\n",
    "y_pred = dt_gini.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_gini\n",
    "accuracy_gini = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print accuracy_gini\n",
    "print('Accuracy achieved by using the gini index: ', accuracy_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your first regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>size</th>\n",
       "      <th>origin_Asia</th>\n",
       "      <th>origin_Europe</th>\n",
       "      <th>origin_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displ   hp  weight  accel  size  origin_Asia  origin_Europe  \\\n",
       "0  18.0  250.0   88    3139   14.5  15.0            0              0   \n",
       "1   9.0  304.0  193    4732   18.5  20.0            0              0   \n",
       "2  36.1   91.0   60    1800   16.4  10.0            1              0   \n",
       "3  18.5  250.0   98    3525   19.0  15.0            0              0   \n",
       "4  34.3   97.0   78    2188   15.8  10.0            0              1   \n",
       "\n",
       "   origin_US  \n",
       "0          1  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('auto.csv')\n",
    "auto.columns\n",
    "auto_origin = pd.get_dummies(auto.origin)\n",
    "auto = pd.concat([auto, auto_origin], axis = 1).drop('origin', axis = 1)\n",
    "auto.columns = ['mpg', 'displ', 'hp', 'weight', 'accel', 'size', 'origin_Asia', 'origin_Europe', 'origin_US']\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = auto[['displ', 'hp', 'weight', 'accel', 'size', 'origin_Asia',\n",
    "       'origin_Europe', 'origin_US']]\n",
    "y = auto['mpg']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=8,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=0.13, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=3, splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeRegressor(max_depth=8,\n",
    "             min_samples_leaf=0.13,\n",
    "            random_state=3)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of dt: 3.59\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute y_pred\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute mse_dt\n",
    "mse_dt = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute rmse_dt\n",
    "rmse_dt = (mse_dt)**0.5\n",
    "\n",
    "# Print rmse_dt\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression vs regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression test set RMSE: 4.16\n"
     ]
    }
   ],
   "source": [
    "# Predict test set labels \n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Compute mse_lr\n",
    "mse_lr = MSE(y_test, y_pred_lr)\n",
    "\n",
    "# Compute rmse_lr\n",
    "rmse_lr = mse_lr**(1/2)\n",
    "\n",
    "# Print rmse_lr\n",
    "print('Linear Regression test set RMSE: {:.2f}'.format(rmse_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set SEED for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate a DecisionTreeRegressor dt\n",
    "dt = DecisionTreeRegressor(max_depth = 4, min_samples_leaf = 0.26, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the 10-fold CV error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 5.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv=10, \n",
    "                                  scoring='neg_mean_squared_error', \n",
    "                                  n_jobs=-1) \n",
    "\n",
    "# Compute the 10-folds CV RMSE\n",
    "RMSE_CV = (MSE_CV_scores.mean())**(1/2)\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 5.15\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "# Evaluate the training set RMSE of dt\n",
    "RMSE_train = (MSE(y_train, y_pred_train))**(0.5)\n",
    "\n",
    "# Print RMSE_train\n",
    "print('Train RMSE: {:.2f}'.format(RMSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "      <th>Liver_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.247403</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.319111</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>1.675083</td>\n",
       "      <td>-0.093573</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>-0.648461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.816243</td>\n",
       "      <td>-0.115428</td>\n",
       "      <td>-0.146459</td>\n",
       "      <td>0.478274</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815511</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.388807</td>\n",
       "      <td>-0.449416</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.312205</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.679294</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.179766</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.930414</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "0  1.247403            -0.420320             -0.495414   \n",
       "1  1.062306             1.218936              1.423518   \n",
       "2  1.062306             0.640375              0.926017   \n",
       "3  0.815511            -0.372106             -0.388807   \n",
       "4  1.679294             0.093956              0.179766   \n",
       "\n",
       "   Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "0                 -0.428870                     -0.355832   \n",
       "1                  1.675083                     -0.093573   \n",
       "2                  0.816243                     -0.115428   \n",
       "3                 -0.449416                     -0.366760   \n",
       "4                 -0.395996                     -0.295731   \n",
       "\n",
       "   Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "0                       -0.319111            0.293722     0.203446   \n",
       "1                       -0.035962            0.939655     0.077462   \n",
       "2                       -0.146459            0.478274     0.203446   \n",
       "3                       -0.312205            0.293722     0.329431   \n",
       "4                       -0.177537            0.755102    -0.930414   \n",
       "\n",
       "   Albumin_and_Globulin_Ratio_std  Is_male_std  Liver_disease  \n",
       "0                       -0.147390            0              1  \n",
       "1                       -0.648461            1              1  \n",
       "2                       -0.178707            1              1  \n",
       "3                        0.165780            1              1  \n",
       "4                       -1.713237            1              1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver = pd.read_csv('indian_liver_patient/indian_liver_patient_preprocessed.csv', index_col = 0)\n",
    "X = liver.drop('Liver_disease', axis = 1)\n",
    "y = liver['Liver_disease']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "liver.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED, solver = 'liblinear')\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNN(n_neighbors=27)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
    "\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate individual classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.764\n",
      "K Nearest Neighbours : 0.701\n",
      "Classification Tree : 0.730\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy =accuracy_score(y_test, y_pred)\n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better performance with a Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.770\n"
     ]
    }
   ],
   "source": [
    "# Import VotingClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Bagging performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, \n",
    "            n_estimators=50,\n",
    "            oob_score=True,\n",
    "            random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOB Score vs Test Set Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.718, OOB accuracy: 0.686\n"
     ]
    }
   ],
   "source": [
    "# Fit bc to the training set \n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "# Print acc_test and acc_oob\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an RF regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>instant</th>\n",
       "      <th>mnth</th>\n",
       "      <th>yr</th>\n",
       "      <th>Clear to partly cloudy</th>\n",
       "      <th>Light Precipitation</th>\n",
       "      <th>Misty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>149</td>\n",
       "      <td>13004</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>93</td>\n",
       "      <td>13005</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>90</td>\n",
       "      <td>13006</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>33</td>\n",
       "      <td>13007</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>4</td>\n",
       "      <td>13008</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hr  holiday  workingday  temp   hum  windspeed  cnt  instant  mnth  yr  \\\n",
       "0   0        0           0  0.76  0.66     0.0000  149    13004     7   1   \n",
       "1   1        0           0  0.74  0.70     0.1343   93    13005     7   1   \n",
       "2   2        0           0  0.72  0.74     0.0896   90    13006     7   1   \n",
       "3   3        0           0  0.72  0.84     0.1343   33    13007     7   1   \n",
       "4   4        0           0  0.70  0.79     0.1940    4    13008     7   1   \n",
       "\n",
       "   Clear to partly cloudy  Light Precipitation  Misty  \n",
       "0                       1                    0      0  \n",
       "1                       1                    0      0  \n",
       "2                       1                    0      0  \n",
       "3                       1                    0      0  \n",
       "4                       1                    0      0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike = pd.read_csv('bikes.csv')\n",
    "X = bike[['hr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'instant',\n",
    "       'mnth', 'yr', 'Clear to partly cloudy', 'Light Precipitation', 'Misty']]\n",
    "y = bike['cnt']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=25, n_jobs=None, oob_score=False,\n",
       "                      random_state=2, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25,\n",
    "            random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the RF regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 51.84\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = (MSE(y_test, y_pred))**0.5\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_,\n",
    "                        index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind = 'barh', color = 'lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth = 2, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liver.drop('Liver_disease', axis = 1)\n",
    "y = liver['Liver_disease']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ada to the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba = ada.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the GB regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "\n",
    "# Instantiate gb\n",
    "gb = GradientBoostingRegressor(max_depth = 4, \n",
    "            n_estimators = 200,\n",
    "            random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the GB regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bike[['hr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'instant',\n",
    "       'mnth', 'yr', 'Clear to partly cloudy', 'Light Precipitation', 'Misty']]\n",
    "y = bike['cnt']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit gb to the training set\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the GB regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of gb: 43.113\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_test = mse_test ** 0.5\n",
    "\n",
    "# Print RMSE\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with SGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate sgbr\n",
    "sgbr = GradientBoostingRegressor(max_depth=4, \n",
    "            subsample=0.9,\n",
    "            max_features=0.75,\n",
    "            n_estimators=200,                                \n",
    "            random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the SGB regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit sgbr to the training set\n",
    "sgbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = sgbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the SGB regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of sgbr: 45.143\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute test set MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute test set RMSE\n",
    "rmse_test = mse_test ** 0.5\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the tree's hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params_dt\n",
    "params_dt = {'max_depth': [2, 3, 4], 'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the optimal tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the optimal tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=1, splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = liver.drop('Liver_disease', axis = 1)\n",
    "y = liver['Liver_disease']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.731\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score from sklearn.metrics \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the hyperparameter grid of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary 'params_rf'\n",
    "params_rf = {'n_estimators': [100, 350, 500], 'max_features': ['log2', 'auto', 'sqrt'], 'min_samples_leaf': [2, 10, 30]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the optimal forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
    "           oob_score=False, random_state=2, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   37.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=10, n_jobs=-1,\n",
       "                                             oob_score=False, random_state=2,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 10, 30],\n",
       "                         'n_estimators': [100, 350, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = bike[['hr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'instant',\n",
    "       'mnth', 'yr', 'Clear to partly cloudy', 'Light Precipitation', 'Misty']]\n",
    "y = bike['cnt']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the optimal forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 51.755\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**0.5\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
